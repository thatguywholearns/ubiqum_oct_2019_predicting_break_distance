test_size <- nrow(dataset_cars) - train_size
training_indices <- sample(seq_len(nrow(dataset_cars)), size = train_size)
training_set <- dataset_cars[training_indices,]
test_set <- dataset_cars[-training_indices,]
#Fit linear model to training data
lm_model1 <- lm(distance_of_car~ speed_of_car_squared, training_set)
lm_model2 <- lm(distance_of_car~ speed_of_car, training_set)
#Show summary for both statistics model
summary(lm_model1)
summary(lm_model2)
#Model 1 has the greatest R squared
#Make predictions for both models on test set
predictions_model1 <- predict(lm_model1, test_set)
predictions_model2 <- predict(lm_model2, test_set)
#Add predictions to dataframe cars
#Calculate error of predictions for both model
#error_model1 <- test_set - predictions_model1
#error_model2 <- test_set - predictions_model2
#Import all used libraries
library(readr)
library(ggplot2)
#Import dataset_cars
dataset_cars <- read.csv('./R Tutorial Data Sets/cars.csv', header = TRUE)
#Inspect the the structure, variables and summary statistics of the dataset_cars
names(dataset_cars)
attributes(x = dataset_cars)
str(dataset_cars)
summary(dataset_cars)
#Rename variables
names(dataset_cars) <- c("name_of_car", "speed_of_car", "distance_of_car")
names(dataset_cars)
#Generate boxplsot to gain better udnerstanding of distribution of the dependant variable
boxplot(dataset_cars$distance_of_car)
#We observe one outlier with a distance greater than 100, we remove this outlier from our dataset
#as it will bias the out prediction
outliers <- boxplot(dataset_cars$distance_of_car, plot=FALSE)$out
dataset_cars <- dataset_cars[which(dataset_cars$distance_of_car %in% outliers),]
View(dataset_cars)
View(dataset_cars)
View(dataset_cars)
View(dataset_cars)
#as it will bias the out prediction
outliers <- boxplot(dataset_cars$distance_of_car, plot=FALSE)$out
dataset_cars <- dataset_cars[-which(dataset_cars$distance_of_car %in% outliers),]
View(dataset_cars)
View(dataset_cars)
#Import all used libraries
library(readr)
library(ggplot2)
#Import dataset_cars
dataset_cars <- read.csv('./R Tutorial Data Sets/cars.csv', header = TRUE)
#Inspect the the structure, variables and summary statistics of the dataset_cars
names(dataset_cars)
attributes(x = dataset_cars)
str(dataset_cars)
summary(dataset_cars)
#Rename variables
names(dataset_cars) <- c("name_of_car", "speed_of_car", "distance_of_car")
#Generate boxplsot to gain better udnerstanding of distribution of the dependant variable
boxplot(dataset_cars$distance_of_car)
#We observe one outlier with a distance greater than 100, we remove this outlier from our dataset
#as it will bias the out prediction
outliers <- boxplot(dataset_cars$distance_of_car, plot=FALSE)$out
dataset_cars <- dataset_cars[-which(dataset_cars$distance_of_car %in% outliers),]
View(dataset_cars)
View(dataset_cars)
#Import all used libraries
library(readr)
library(ggplot2)
#Import dataset_cars
dataset_cars <- read.csv('./R Tutorial Data Sets/cars.csv', header = TRUE)
#Inspect the the structure, variables and summary statistics of the dataset_cars
names(dataset_cars)
attributes(x = dataset_cars)
str(dataset_cars)
summary(dataset_cars)
#Rename variables
names(dataset_cars) <- c("name_of_car", "speed_of_car", "distance_of_car")
#Generate boxplsot to gain better udnerstanding of distribution of the dependant variable
boxplot(dataset_cars$distance_of_car)
#We observe one outlier with a distance greater than 100, we remove this outlier from our dataset
#as it will bias the out prediction
outliers <- boxplot(dataset_cars$distance_of_car, plot=FALSE)$out
dataset_cars <- dataset_cars[-which(dataset_cars$distance_of_car %in% outliers),]
#Generate plot in order to see patterns and correlations
plot(dataset_cars$distance_of_car, dataset_cars$speed_of_car)
#We see that there is a quadratic relationship between speed of car and distance of car.
#Transform the data in such a way that the relationship becomes linear. To do so, we need to
#square the independant variale car speed.
dataset_cars$speed_of_car_squared <- dataset_cars$speed_of_car*dataset_cars$speed_of_car
#Check whether transformation was succesful
names(dataset_cars)
str(dataset_cars$speed_of_car_squared)
#Regenerate plots in order to see if transformation worked
plot(dataset_cars$distance_of_car, dataset_cars$speed_of_car_squared)
#Set random seed of the script to 123
set.seed(256)
#Create training set and test set by using a 70/30 split
train_size <- round(nrow(dataset_cars)*0.70)
test_size <- nrow(dataset_cars) - train_size
training_indices <- sample(seq_len(nrow(dataset_cars)), size = train_size)
training_set <- dataset_cars[training_indices,]
test_set <- dataset_cars[-training_indices,]
#Fit linear model to training data
lm_model1 <- lm(distance_of_car~ speed_of_car_squared, training_set)
lm_model2 <- lm(distance_of_car~ speed_of_car, training_set)
#Show summary for both statistics model
summary(lm_model1)
summary(lm_model2)
#Model 1 has the greatest R squared
#Make predictions for both models on test set
predictions_model1 <- predict(lm_model1, test_set)
predictions_model2 <- predict(lm_model2, test_set)
#Add predictions to dataframe cars
#Calculate error of predictions for both model
#error_model1 <- test_set - predictions_model1
#error_model2 <- test_set - predictions_model2
boxplot(dataset_cars$distance_of_car, horizontal = FALSE)
boxplot(dataset_cars$distance_of_car)
#Import all used libraries
library(readr)
library(ggplot2)
#Import dataset_cars
dataset_cars <- read.csv('./R Tutorial Data Sets/cars.csv', header = TRUE)
#Inspect the the structure, variables and summary statistics of the dataset_cars
names(dataset_cars)
attributes(x = dataset_cars)
str(dataset_cars)
summary(dataset_cars)
#Rename variables
names(dataset_cars) <- c("name_of_car", "speed_of_car", "distance_of_car")
#Generate boxplsot to gain better udnerstanding of distribution of the dependant variable
boxplot(dataset_cars$distance_of_car)
boxplot(dataset_cars$distance_of_car, nothc = TRUE)
source('~/Documents/R Files/Ubiqum/Module 2/Task 1/Cars.R', echo=TRUE)
boxplot(dataset_cars$distance_of_car, notch = TRUE)
boxplot(dataset_cars$distance_of_car, notch = FALSE, names)
boxplot(dataset_cars$distance_of_car, notch = FALSE, names = "Distance")
boxplot(dataset_cars$distance_of_car, notch = FALSE)
boxplot(dataset_cars$distance_of_car, notch = FALSE, xlab("Distance"
?boxplot
#Generate boxplsot to gain better udnerstanding of distribution of the dependant variable
?boxplot
ggplot(dataset_cars, aes(distance_of_car)) + geom_boxplot()
#Import all used libraries
library(readr)
library(ggplot2)
ggplot(dataset_cars, aes(distance_of_car)) + geom_boxplot()
distance_of_car
ggplot(dataset_cars, aes(distance_of_car)) + geom_boxplot()
ggplot(dataset_cars, aes()) + geom_boxplot()
names(dataset_cars) <- c("name_of_car", "speed_of_car", "distance_of_car")
#Import all used libraries
library(readr)
library(ggplot2)
#Import dataset_cars
dataset_cars <- read.csv('./R Tutorial Data Sets/cars.csv', header = TRUE)
#Inspect the the structure, variables and summary statistics of the dataset_cars
names(dataset_cars)
attributes(x = dataset_cars)
str(dataset_cars)
summary(dataset_cars)
#Rename variables
names(dataset_cars) <- c("name_of_car", "speed_of_car", "distance_of_car")
#Generate boxplsot to gain better udnerstanding of distribution of the dependant variable
ggplot(dataset_cars, aes(distance_of_car)) + geom_boxplot()
ggplot(dataset_cars, aes(distance_of_car, speed_of_car)) + geom_boxplot()
ggplot(dataset_cars, aes(distance_of_car)) + geom_boxplot()
ggplot(dataset_cars, aes(distance_of_car)) + geom_boxplot(distance_of_car)
ggplot(dataset_cars, aes(y = distance_of_car)) + geom_boxplot()
ggplot(dataset_cars, aes(y = distance_of_car)) + geom_boxplot(utlier.colour="red", outlier.shape=8,
outlier.size=4)
ggplot(dataset_cars, aes(y = distance_of_car, x="")) + geom_boxplot(utlier.colour="red", outlier.shape=8,
#Generate boxplsot to gain better udnerstanding of distribution of the dependant variable
ggplot(dataset_cars, aes(y = distance_of_car, x="")) + geom_boxplot(utlier.colour="red", outlier.shape=8,
outlier.size=4)
#Generate boxplsot to gain better udnerstanding of distribution of the dependant variable
ggplot(dataset_cars, aes(y = distance_of_car, x="")) + geom_boxplot(outlier.colour="red", outlier.shape=8,
outlier.size=4)
ggplot(dataset_cars, aes(y = distance_of_car, x="")) + geom_boxplot(outlier.colour="red", outlier.shape=8, outlier.size=4)
ggplot(dataset_cars, aes(y = distance_of_car, x=" ")) + geom_boxplot(outlier.colour="red", outlier.shape=8, outlier.size=4)
ggplot(dataset_cars, aes(y = distance_of_car, x="BOXPLOT")) + geom_boxplot(outlier.colour="red", outlier.shape=8, outlier.size=4)
ggplot(dataset_cars, aes(y = distance_of_car)) + geom_boxplot(outlier.colour="red", outlier.shape=8, outlier.size=4)
install.packages("rmdformats")
install.packages("prettydoc")
summary(lm_model2)pairs(dataset_cars)
#Import all used libraries
library(readr)
library(ggplot2)
#Import dataset_cars
dataset_cars <- read.csv('./R Tutorial Data Sets/cars.csv', header = TRUE)
#Inspect the the structure, variables and summary statistics of the dataset_cars
names(dataset_cars)
attributes(x = dataset_cars)
str(dataset_cars)
summary(dataset_cars)
#Rename variables
names(dataset_cars) <- c("name_of_car", "speed_of_car", "distance_of_car")
#Generate boxplsot to gain better udnerstanding of distribution of the dependant variable
ggplot(dataset_cars, aes(y = distance_of_car)) + geom_boxplot(outlier.colour="red", outlier.shape=8, outlier.size=4)
#We observe one outlier with a distance greater than 100, we remove this outlier from our dataset
#as it will bias the out prediction
outliers <- boxplot(dataset_cars$distance_of_car, plot=FALSE)$out
dataset_cars <- dataset_cars[-which(dataset_cars$distance_of_car %in% outliers),]
#Generate plot in order to see patterns and correlations
plot(dataset_cars$distance_of_car, dataset_cars$speed_of_car)
#We see that there is a quadratic relationship between speed of car and distance of car.
#Transform the data in such a way that the relationship becomes linear. To do so, we need to
#square the independant variale car speed.
dataset_cars$speed_of_car_squared <- dataset_cars$speed_of_car*dataset_cars$speed_of_car
#Check whether transformation was succesful
names(dataset_cars)
str(dataset_cars$speed_of_car_squared)
#Regenerate plots in order to see if transformation worked
plot(dataset_cars$distance_of_car, dataset_cars$speed_of_car_squared)
#Set random seed of the script to 123
set.seed(256)
#Create training set and test set by using a 70/30 split
train_size <- round(nrow(dataset_cars)*0.70)
test_size <- nrow(dataset_cars) - train_size
training_indices <- sample(seq_len(nrow(dataset_cars)), size = train_size)
training_set <- dataset_cars[training_indices,]
test_set <- dataset_cars[-training_indices,]
#Fit linear model to training data
lm_model1 <- lm(distance_of_car~ speed_of_car_squared, training_set)
lm_model2 <- lm(distance_of_car~ speed_of_car, training_set)
#Show summary for both statistics model
summary(lm_model1)
summary(lm_model2)pairs(dataset_cars)
#Model 1 has the greatest R squared
#Make predictions for both models on test set
predictions_model1 <- predict(lm_model1, test_set)
predictions_model2 <- predict(lm_model2, test_set)
#Add predictions to dataframe cars
#Calculate error of predictions for both model
#error_model1 <- test_set - predictions_model1
#error_model2 <- test_set - predictions_model2
#Import all used libraries
library(readr)
library(ggplot2)
#Import dataset_cars
dataset_cars <- read.csv('./R Tutorial Data Sets/cars.csv', header = TRUE)
#Inspect the the structure, variables and summary statistics of the dataset_cars
names(dataset_cars)
attributes(x = dataset_cars)
str(dataset_cars)
summary(dataset_cars)
#Rename variables
names(dataset_cars) <- c("name_of_car", "speed_of_car", "distance_of_car")
#Generate boxplsot to gain better udnerstanding of distribution of the dependant variable
ggplot(dataset_cars, aes(y = distance_of_car)) + geom_boxplot(outlier.colour="red", outlier.shape=8, outlier.size=4)
#We observe one outlier with a distance greater than 100, we remove this outlier from our dataset
#as it will bias the out prediction
outliers <- boxplot(dataset_cars$distance_of_car, plot=FALSE)$out
dataset_cars <- dataset_cars[-which(dataset_cars$distance_of_car %in% outliers),]
#Generate plot in order to see patterns and correlations
plot(dataset_cars$distance_of_car, dataset_cars$speed_of_car)
#We see that there is a quadratic relationship between speed of car and distance of car.
#Transform the data in such a way that the relationship becomes linear. To do so, we need to
#square the independant variale car speed.
dataset_cars$speed_of_car_squared <- dataset_cars$speed_of_car*dataset_cars$speed_of_car
#Check whether transformation was succesful
names(dataset_cars)
str(dataset_cars$speed_of_car_squared)
#Regenerate plots in order to see if transformation worked
plot(dataset_cars$distance_of_car, dataset_cars$speed_of_car_squared)
#Set random seed of the script to 123
set.seed(256)
#Create training set and test set by using a 70/30 split
train_size <- round(nrow(dataset_cars)*0.70)
test_size <- nrow(dataset_cars) - train_size
training_indices <- sample(seq_len(nrow(dataset_cars)), size = train_size)
training_set <- dataset_cars[training_indices,]
test_set <- dataset_cars[-training_indices,]
#Fit linear model to training data
lm_model1 <- lm(distance_of_car~ speed_of_car_squared, training_set)
lm_model2 <- lm(distance_of_car~ speed_of_car, training_set)
#Show summary for both statistics model
summary(lm_model1)
summary(lm_model2)
pairs(dataset_cars)
#Model 1 has the greatest R squared
#Make predictions for both models on test set
predictions_model1 <- predict(lm_model1, test_set)
predictions_model2 <- predict(lm_model2, test_set)
#Add predictions to dataframe cars
#Calculate error of predictions for both model
#error_model1 <- test_set - predictions_model1
#error_model2 <- test_set - predictions_model2
#Import all used libraries
library(readr)
library(ggplot2)
#Import dataset_cars
dataset_cars <- read.csv('./R Tutorial Data Sets/cars.csv', header = TRUE)
#Inspect the the structure, variables and summary statistics of the dataset_cars
names(dataset_cars)
attributes(x = dataset_cars)
str(dataset_cars)
summary(dataset_cars)
#Rename variables
names(dataset_cars) <- c("name_of_car", "speed_of_car", "distance_of_car")
#Generate boxplsot to gain better udnerstanding of distribution of the dependant variable
ggplot(dataset_cars, aes(y = distance_of_car)) + geom_boxplot(outlier.colour="red", outlier.shape=8, outlier.size=4)
#We observe one outlier with a distance greater than 100, we remove this outlier from our dataset
#as it will bias the out prediction
outliers <- boxplot(dataset_cars$distance_of_car, plot=FALSE)$out
dataset_cars <- dataset_cars[-which(dataset_cars$distance_of_car %in% outliers),]
#Generate plot in order to see patterns and correlations
plot(dataset_cars$distance_of_car, dataset_cars$speed_of_car)
#We see that there is a quadratic relationship between speed of car and distance of car.
#Transform the data in such a way that the relationship becomes linear. To do so, we need to
#square the independant variale car speed.
dataset_cars$speed_of_car_squared <- dataset_cars$speed_of_car*dataset_cars$speed_of_car
#Check whether transformation was succesful
names(dataset_cars)
str(dataset_cars$speed_of_car_squared)
#Regenerate plots in order to see if transformation worked
plot(dataset_cars$distance_of_car, dataset_cars$speed_of_car_squared)
#Set random seed of the script to 123
set.seed(256)
#Create training set and test set by using a 70/30 split
train_size <- round(nrow(dataset_cars)*0.70)
test_size <- nrow(dataset_cars) - train_size
training_indices <- sample(seq_len(nrow(dataset_cars)), size = train_size)
training_set <- dataset_cars[training_indices,]
test_set <- dataset_cars[-training_indices,]
#Fit linear model to training data
lm_model1 <- lm(distance_of_car~ speed_of_car_squared, training_set)
lm_model2 <- lm(distance_of_car~ speed_of_car, training_set)
#Show summary for both statistics model
summary(lm_model1)
summary(lm_model2)
#Model 1 has the greatest R squared
#Make predictions for both models on test set
predictions_model1 <- predict(lm_model1, test_set)
predictions_model2 <- predict(lm_model2, test_set)
#Add predictions to dataframe cars
#Calculate error of predictions for both model
#error_model1 <- test_set - predictions_model1
#error_model2 <- test_set - predictions_model2
#Import all used libraries
library(readr)
library(ggplot2)
#Import dataset_cars
dataset_cars <- read.csv('./R Tutorial Data Sets/cars.csv', header = TRUE)
#Inspect the the structure, variables and summary statistics of the dataset_cars
names(dataset_cars)
attributes(x = dataset_cars)
str(dataset_cars)
summary(dataset_cars)
#Rename variables
names(dataset_cars) <- c("name_of_car", "speed_of_car", "distance_of_car")
#Generate boxplsot to gain better udnerstanding of distribution of the dependant variable
ggplot(dataset_cars, aes(y = distance_of_car)) + geom_boxplot(outlier.colour="red", outlier.shape=8, outlier.size=4)
#We observe one outlier with a distance greater than 100, we remove this outlier from our dataset
#as it will bias the out prediction
outliers <- boxplot(dataset_cars$distance_of_car, plot=FALSE)$out
dataset_cars <- dataset_cars[-which(dataset_cars$distance_of_car %in% outliers),]
#Generate plot in order to see patterns and correlations
plot(dataset_cars$distance_of_car, dataset_cars$speed_of_car)
#We see that there is a quadratic relationship between speed of car and distance of car.
#Transform the data in such a way that the relationship becomes linear. To do so, we need to
#square the independant variale car speed.
dataset_cars$speed_of_car_squared <- dataset_cars$speed_of_car*dataset_cars$speed_of_car
#Check whether transformation was succesful
names(dataset_cars)
str(dataset_cars$speed_of_car_squared)
#Regenerate plots in order to see if transformation worked
plot(dataset_cars$distance_of_car, dataset_cars$speed_of_car_squared)
#Set random seed of the script to 123
set.seed(256)
#Create training set and test set by using a 70/30 split
train_size <- round(nrow(dataset_cars)*0.70)
test_size <- nrow(dataset_cars) - train_size
training_indices <- sample(seq_len(nrow(dataset_cars)), size = train_size)
training_set <- dataset_cars[training_indices,]
test_set <- dataset_cars[-training_indices,]
#Fit linear model to training data
lm_model1 <- lm(distance_of_car~ speed_of_car_squared, training_set)
lm_model2 <- lm(distance_of_car~ speed_of_car, training_set)
#Show summary for both statistics model
summary(lm_model1)
summary(lm_model2)
#Model 1 has the greatest R squared
#Make predictions for both models on test set
predictions_model1 <- predict(lm_model1, test_set)
predictions_model2 <- predict(lm_model2, test_set)
#Add predictions to dataframe cars
#Calculate error of predictions for both model
#error_model1 <- test_set - predictions_model1
#error_model2 <- test_set - predictions_model2
plot(dataset_cars$distance_of_car, dataset_cars$speed_of_car)
dataset_cars$speed_of_car_squared <- dataset_cars$speed_of_car*dataset_cars$speed_of_car
plot(dataset_cars$distance_of_car, dataset_cars$speed_of_car_squared)
#Import all used libraries
library(readr)
library(ggplot2)
#Import dataset_cars
dataset_cars <- read.csv('./R Tutorial Data Sets/cars.csv', header = TRUE)
#Inspect the the structure, variables and summary statistics of the dataset_cars
names(dataset_cars)
attributes(x = dataset_cars)
str(dataset_cars)
summary(dataset_cars)
#Rename variables
names(dataset_cars) <- c("name_of_car", "speed_of_car", "distance_of_car")
#Generate boxplsot to gain better udnerstanding of distribution of the dependant variable
ggplot(dataset_cars, aes(y = distance_of_car)) + geom_boxplot(outlier.colour="red", outlier.shape=8, outlier.size=4)
#We observe one outlier with a distance greater than 100, we remove this outlier from our dataset
#as it will bias the out prediction
outliers <- boxplot(dataset_cars$distance_of_car, plot=FALSE)$out
dataset_cars <- dataset_cars[-which(dataset_cars$distance_of_car %in% outliers),]
#Generate plot in order to see patterns and correlations
plot(dataset_cars$distance_of_car, dataset_cars$speed_of_car)
#We see that there is a quadratic relationship between speed of car and distance of car.
#Transform the data in such a way that the relationship becomes linear. To do so, we need to
#square the independant variale car speed.
dataset_cars$speed_of_car_squared <- dataset_cars$speed_of_car*dataset_cars$speed_of_car
#Check whether transformation was succesful
names(dataset_cars)
str(dataset_cars$speed_of_car_squared)
#Regenerate plots in order to see if transformation worked
plot(dataset_cars$distance_of_car, dataset_cars$speed_of_car_squared)
#Set random seed of the script to 123
set.seed(256)
#Create training set and test set by using a 70/30 split
train_size <- round(nrow(dataset_cars)*0.70)
test_size <- nrow(dataset_cars) - train_size
training_indices <- sample(seq_len(nrow(dataset_cars)), size = train_size)
training_set <- dataset_cars[training_indices,]
test_set <- dataset_cars[-training_indices,]
#Fit linear model to training data
lm_model1 <- lm(distance_of_car~ speed_of_car_squared, training_set)
lm_model2 <- lm(distance_of_car~ speed_of_car, training_set)
#Show summary for both statistics model
summary(lm_model1)
summary(lm_model2)
#Model 1 has the greatest R squared
#Make predictions for both models on test set
predictions_model1 <- predict(lm_model1, test_set)
predictions_model2 <- predict(lm_model2, test_set)
#Add predictions to dataframe cars
#Calculate error of predictions for both model
#error_model1 <- test_set - predictions_model1
#error_model2 <- test_set - predictions_model2
View(lm_model1)
View(lm_model1)
summary(lm_model1)
fitMeasures(lm_model1)
#Check the fit measures
fitMeasures(lm_model1)
#Show summary for both statistics model
summary(lm_model1)
summary(lm_model2)
#Model 1 has the greatest R squared
#Make predictions for both models on test set
predictions_model1 <- predict(lm_model1, test_set)
predictions_model2 <- predict(lm_model2, test_set)
#Add predictions to dataframe cars
#Import all used libraries
library(readr)
library(ggplot2)
#Import dataset_cars
dataset_cars <- read.csv('./R Tutorial Data Sets/cars.csv', header = TRUE)
#Inspect the the structure, variables and summary statistics of the dataset_cars
names(dataset_cars)
attributes(x = dataset_cars)
str(dataset_cars)
summary(dataset_cars)
#Rename variables
names(dataset_cars) <- c("name_of_car", "speed_of_car", "distance_of_car")
#Generate boxplsot to gain better udnerstanding of distribution of the dependant variable
ggplot(dataset_cars, aes(y = distance_of_car)) + geom_boxplot(outlier.colour="red", outlier.shape=8, outlier.size=4)
#We observe one outlier with a distance greater than 100, we remove this outlier from our dataset
#as it will bias the out prediction
outliers <- boxplot(dataset_cars$distance_of_car, plot=FALSE)$out
dataset_cars <- dataset_cars[-which(dataset_cars$distance_of_car %in% outliers),]
#Generate plot in order to see patterns and correlations
plot(dataset_cars$distance_of_car, dataset_cars$speed_of_car)
#We see that there is a quadratic relationship between speed of car and distance of car.
#Transform the data in such a way that the relationship becomes linear. To do so, we need to
#square the independant variale car speed.
dataset_cars$speed_of_car_squared <- dataset_cars$speed_of_car*dataset_cars$speed_of_car
#Check whether transformation was succesful
names(dataset_cars)
str(dataset_cars$speed_of_car_squared)
#Regenerate plots in order to see if transformation worked
plot(dataset_cars$distance_of_car, dataset_cars$speed_of_car_squared)
#Set random seed of the script to 123
set.seed(256)
#Create training set and test set by using a 70/30 split
train_size <- round(nrow(dataset_cars)*0.70)
test_size <- nrow(dataset_cars) - train_size
training_indices <- sample(seq_len(nrow(dataset_cars)), size = train_size)
training_set <- dataset_cars[training_indices,]
test_set <- dataset_cars[-training_indices,]
#Fit linear model to training data
lm_model1 <- lm(distance_of_car~ speed_of_car_squared, training_set)
lm_model2 <- lm(distance_of_car~ speed_of_car, training_set)
#Check the fit measures
fitMeasures(lm_model1)
#Show summary for both statistics model
summary(lm_model1)
summary(lm_model2)
#Model 1 has the greatest R squared
#Make predictions for both models on test set
predictions_model1 <- predict(lm_model1, test_set)
predictions_model2 <- predict(lm_model2, test_set)
#Add predictions to dataframe cars
#Calculate error of predictions for both model
#error_model1 <- test_set - predictions_model1
#error_model2 <- test_set - predictions_model2
